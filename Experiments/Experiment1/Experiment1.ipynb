{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Implementation of Experiments for Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-------------------------Setting the randomness-------#\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "#------------------------------------------------------#\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation,Reshape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.417022   0.72032449]\n"
     ]
    }
   ],
   "source": [
    "num1=np.random.rand(2)\n",
    "print(num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.417022   0.72032449]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "num2=np.random.rand(2)\n",
    "print(num2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "train_data = load('../../Processed_Dataset/training_data.npy')\n",
    "test_data = load('../../Processed_Dataset/testing_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "1341\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0:5,0:1])\n",
    "# print(train_data[3875])\n",
    "print(len(train_data[3875:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.03137255 0.04705882 ... 0.         0.         0.        ]\n",
      "[0.         0.12156863 0.12156863 ... 0.1254902  0.12941177 0.13333334]\n"
     ]
    }
   ],
   "source": [
    "print(test_data[389])\n",
    "print(test_data[390])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Method to choose balancing of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced(option):\n",
    "    if(option==\"yes\"):\n",
    "        training_data = np.concatenate((train_data[0:1341],train_data[3875:]),axis=0)\n",
    "        testing_data = np.concatenate((test_data[0:234],test_data[390:]))\n",
    "        #training_data = train_data\n",
    "        return training_data,testing_data\n",
    "    else:\n",
    "        training_data = train_data\n",
    "        testing_data = np.concatenate((test_data[0:234],test_data[390:]))\n",
    "        return training_data,testing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 62501)\n",
      "(468, 62501)\n"
     ]
    }
   ],
   "source": [
    "training_data,test_data=balanced(\"no\")\n",
    "print(training_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to shuffle the data to allow the Model to learn in a varied manner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffling the data to make it more varied with yes or no to shuffling\n",
    "def ShuffelData(data,option):\n",
    "    if(option==\"yes\"):\n",
    "        data = shuffle(data,random_state=0)\n",
    "        return data\n",
    "    else:\n",
    "        return data\n",
    "training_data = ShuffelData(training_data,\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data[0:,1:]\n",
    "Y_train = training_data[0:,0:1]\n",
    "X_test = test_data[0:,1:]\n",
    "Y_test = test_data[0:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ohe = keras.utils.to_categorical(Y_train, 2)\n",
    "y_test_ohe = keras.utils.to_categorical(Y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5216"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 250, 250)\n",
      "(468, 250, 250)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],250,250)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0],250,250)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_train = np.concatenate((X_train,)*3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbArray = np.dstack((X_train,X_train,X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5216, 250, 750)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgbArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (250,250,1) into shape (5216,250,250)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a66febac36d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrgbArray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (250,250,1) into shape (5216,250,250)"
     ]
    }
   ],
   "source": [
    "rgbArray[...,0] = X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) ..\\modules\\core\\src\\merge.dispatch.cpp:134: error: (-215:Assertion failed) 0 < cn && cn <= CV_CN_MAX in function 'cv::merge'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2dd6a4d6cc4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) ..\\modules\\core\\src\\merge.dispatch.cpp:134: error: (-215:Assertion failed) 0 < cn && cn <= CV_CN_MAX in function 'cv::merge'\n"
     ]
    }
   ],
   "source": [
    "X_train = cv2.merge((X_train,X_train,X_train))\n",
    "X_test = cv2.merge((X_test,X_test,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 2D CNN \n",
    "\n",
    "## 1. Define Sequential Model\n",
    "## 2. Add 2D CNN with 32 filters,3x3 filters\n",
    "## 3. Apply Relu\n",
    "## 4. Apply Batch Norm\n",
    "## Repeat x2\n",
    "## 5. Apply MaxPooling(2,2)\n",
    "## 6. Send through Fully Connected Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model_CNN = Sequential()\n",
    "    \n",
    "    model_CNN.add(Conv2D(32,(3,3),input_shape=(250,250,1)))\n",
    "    model_CNN.add(Activation('relu')) # Remember, Batch Norm is meant to go before activation. However, for purposes of recreating experriment 1 keep Batch Norm after activation\n",
    "    \n",
    "    model_CNN.add(Conv2D(32, (3, 3)))\n",
    "    model_CNN.add(Activation('relu'))\n",
    "\n",
    "    model_CNN.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model_CNN.add(Flatten())# Flattens the output from the previos layer\n",
    "\n",
    "    # Fully connected layer\n",
    "    model_CNN.add(Dense(128))\n",
    "    model_CNN.add(Activation('relu'))\n",
    "    #model_CNN.add(Dropout(0.2))\n",
    "    model_CNN.add(Dense(2))\n",
    "    model_CNN.add(Activation('softmax'))\n",
    "    \n",
    "    return model_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(create_model().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for the experiment below\n",
    "\n",
    "## 1. Model is ran with the above architeture \n",
    "## 2.Trained on Imbalanced Set\n",
    "## 3. Tested on Balanced Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a test to see if running 10 experiments for the same setup of model produces the same results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = []\n",
    "# for i in range(0,10):\n",
    "#     model = create_model() \n",
    "#     opt = optimizers.Adam(lr=0.01)\n",
    "#     model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "#     model.fit(X_train, y_train_ohe,batch_size=64,epochs=25,validation_data=(X_test, y_test_ohe))# model\n",
    "#     score = model.evaluate(X_test, y_test_ohe)\n",
    "#     accuracy.append(round(score[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "opt = optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_ohe,batch_size=64,epochs=1,validation_data=(X_test, y_test_ohe))# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting accuracy\n",
    "## Remember to UNCOMMENT the .savefig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "#plt.savefig('train_vs_test_accuracy_shuffled.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What does the above graph tell us about the model \n",
    "## -> What we see is that when it comes to training the model, it has high accuracy on the training set.\n",
    "# However when looking at the testing accuracy we can see the accuracy after every epoch is quite volatile. \n",
    "# What this tell us is that the model has clearly not been able to learn from training data. When looking at the graph it also shows overfitting \n",
    "## But this comes secondary to the concept of the model actually underfitting even though the the accuracy on the training data is high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.savefig('train_vs_test_loss_shuffled.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test_ohe)\n",
    "print('Loss ' , score[0])\n",
    "print('Test accuracy: ', score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Visualise the output of Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = [\"TN\",\"FP\"],[\"FN\",\"TP\"]\n",
    "print(matrix[0])\n",
    "print(matrix[1])\n",
    "\n",
    "##Lets Visualise the output\n",
    "conf=confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(conf)\n",
    "# or we can use a heatmap from the seaborn library\n",
    "#import seaborn as sn\n",
    "#df_cm = pandas.DataFrame(conf, range(2), range(2))\n",
    "#sn.set(font_scale=1.4)#for label size\n",
    "#sn.heatmap(df_cm, cmap=\"YlGnBu\", annot=True, annot_kws={\"size\": 20},fmt=\"d\")# font size\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
