{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Implementation of Experiments for Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0410 22:32:41.152760 140521505519424 module_wrapper.py:136] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/module_wrapper.py:163: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-------------------------Setting the randomness-------#\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "#------------------------------------------------------#\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation,Reshape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "train_data = load('data/training_data.npy')\n",
    "test_data = load('data/testing_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "1341\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0:5,0:1])\n",
    "# print(train_data[3875])\n",
    "print(len(train_data[3875:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.03137255 0.04705882 ... 0.         0.         0.        ]\n",
      "[0.         0.12156863 0.12156863 ... 0.1254902  0.12941177 0.13333334]\n"
     ]
    }
   ],
   "source": [
    "print(test_data[389])\n",
    "print(test_data[390])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Method to choose balancing of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced(option):\n",
    "    if(option==\"yes\"):\n",
    "        training_data = np.concatenate((train_data[0:1341],train_data[3875:]),axis=0)\n",
    "        testing_data = np.concatenate((test_data[0:234],test_data[390:]))\n",
    "        #training_data = train_data\n",
    "        return training_data,testing_data\n",
    "    else:\n",
    "        training_data = train_data\n",
    "        testing_data = np.concatenate((test_data[0:234],test_data[390:]))\n",
    "        return training_data,testing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 62501)\n",
      "(468, 62501)\n"
     ]
    }
   ],
   "source": [
    "training_data,test_data=balanced(\"no\")\n",
    "print(training_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to shuffle the data to allow the Model to learn in a varied manner\n",
    "### Note: This experiment did not shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffling the data to make it more varied with yes or no to shuffling\n",
    "def ShuffelData(data,option):\n",
    "    if(option==\"yes\"):\n",
    "        data = shuffle(data,random_state=0)\n",
    "        return data\n",
    "    else:\n",
    "        return data\n",
    "training_data = ShuffelData(training_data,\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data[0:,1:]\n",
    "Y_train = training_data[0:,0:1]\n",
    "X_test = test_data[0:,1:]\n",
    "Y_test = test_data[0:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ohe = keras.utils.to_categorical(Y_train, 2)\n",
    "y_test_ohe = keras.utils.to_categorical(Y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5216"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 250, 250, 1)\n",
      "(468, 250, 250, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],250,250,1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0],250,250,1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 2D CNN \n",
    "\n",
    "## 1. Define Sequential Model\n",
    "## 2. Add 2D CNN with 32 filters,3x3 filters\n",
    "## 3. Apply Relu\n",
    "## Repeat x2\n",
    "## 4. Apply MaxPooling(2,2)\n",
    "## 5. Send through Fully Connected Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model_CNN = Sequential()\n",
    "    \n",
    "    model_CNN.add(Conv2D(32,(3,3),input_shape=(250,250,1)))\n",
    "    model_CNN.add(Activation('relu')) # Remember, Batch Norm is meant to go before activation. However, for purposes of recreating experriment 1 keep Batch Norm after activation\n",
    "    \n",
    "    model_CNN.add(Conv2D(32, (3, 3)))\n",
    "    model_CNN.add(Activation('relu'))\n",
    "\n",
    "    model_CNN.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model_CNN.add(Flatten())# Flattens the output from the previos layer\n",
    "\n",
    "    # Fully connected layer\n",
    "    model_CNN.add(Dense(128))\n",
    "    model_CNN.add(Activation('relu'))\n",
    "    #model_CNN.add(Dropout(0.2))\n",
    "    model_CNN.add(Dense(2))\n",
    "    model_CNN.add(Activation('softmax'))\n",
    "    \n",
    "    return model_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(create_model().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for the experiment below\n",
    "\n",
    "## 1. Model is ran with the above architeture \n",
    "## 2.Trained on Imbalanced Set\n",
    "## 3. Tested on Balanced Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0410 22:09:50.976075 140662387439424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:550: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Apply a constraint manually following the optimizer update step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 468 samples\n",
      "Epoch 1/1\n",
      "5216/5216 [==============================] - 11s 2ms/step - loss: 13.1794 - accuracy: 0.7308 - val_loss: 0.8186 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "opt = optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_ohe,batch_size=64,epochs=1,validation_data=(X_test, y_test_ohe))# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Visualise the output of Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TN', 'FP']\n",
      "['FN', 'TP']\n",
      "Confusion Matrix\n",
      "[[  0 234]\n",
      " [  0 234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       234\n",
      "         1.0       0.50      1.00      0.67       234\n",
      "\n",
      "    accuracy                           0.50       468\n",
      "   macro avg       0.25      0.50      0.33       468\n",
      "weighted avg       0.25      0.50      0.33       468\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = [\"TN\",\"FP\"],[\"FN\",\"TP\"]\n",
    "print(matrix[0])\n",
    "print(matrix[1])\n",
    "\n",
    "##Lets Visualise the output\n",
    "conf=confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\")\n",
    "print(conf)\n",
    "# or we can use a heatmap from the seaborn library\n",
    "#import seaborn as sn\n",
    "#df_cm = pandas.DataFrame(conf, range(2), range(2))\n",
    "#sn.set(font_scale=1.4)#for label size\n",
    "#sn.heatmap(df_cm, cmap=\"YlGnBu\", annot=True, annot_kws={\"size\": 20},fmt=\"d\")# font size\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
